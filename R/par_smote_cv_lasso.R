#' Stratified cross-validation with SMOTE for LASSO using parallel computing
#'
#' This function uses parallel computing to fit k-fold cross-validation for LASSO regression on datasets with an imbalanced binary outcome, where the training sets in each fold is SMOTEd, and returns a value for \eqn{\lambda}.
#'
#' @param X feature matrix or \code{smote_cv_dataList} generated by function \code{stratified_cv_smote}
#' @param y binary outcome, where 1 = positive event & minority class and 0 = negative event & majority class; ignored if \code{x} is \code{smote_cv_dataList}.
#' @param nlambda number of \code{lambda} values, default value is 100.
#' @param lambda user supplied \code{lambda} sequence, typically computed by program based on \code{nlambda} and input data.
#' @param thresh convergence threshold for coordinate descent, default value is \code{1E-7}
#' @param maxit maximum number of passes over the data for all lambda values; default is \code{1E5}
#' @param \dots other arguments that can be passed to \code{stratified_cv_smote} or \code{glmnet}
#'
#' @examples
#' # example code
#'
#' @export

par_smote_cv_lasso <- function(
    X,
    y = NULL,
    nlambda = 100,
    lambda = NULL,
    thresh = 1e7,
    maxit = 1e5,
    ...
) {
  # check whether input X is a featured list or a matrix
  if(!(is(X, "smote_cv_dataList"))) {
    if(!is.matrix(X)) {
      if(is.data.frame(X)) X <- as.matrix(X)
      else stop("X should be either a smote_cv_dataList or a matrix.")
    } else {
      if(is.null(y))
        stop("Input y is required given input X is a matrix!")
      else {
        X <- stratified_cv_smote(X, y, ...)
      }
    }
  }

  X1 <- do.call(rbind, X$test) |> as.matrix()
  if(is.null(lambda)) lambda <- lambda_gen(X1[, -ncol(X1)], X1[, ncol(X1)], K = nlambda)

  cores <- min(length(X$test), parallel::detectCores() - 1)
  cl <- parallel::makeCluster(cores)
  on.exit(parallel::stopCluster(cl))
  parallel::clusterExport(cl, "X")
  res <- parallel::parSapply(cl, seq(length(X$test)), \(i) {
    testdata <- X$test[[i]]
    traindata <- X$train[[i]]
    nX <- ncol(testdata) - 1
    fit <- glmnet(traindata[, 1:nX], traindata[, nx+1], family = "binomial", lambda = lambda, thresh = thresh, maxit = maxit, ...)
    pred <- pred(fit, newx = testdata[, 1:nX], s = lambda)
    apply(pred, 2, \(x) mean((x-testdata[, nx+1]) ^ 2))
  })


  class(res) <- c("smote_cv_mseMatrix", "matrix")
  return(res)
}
