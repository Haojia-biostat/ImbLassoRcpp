---
title: "Introduction to parameter tuning and regression"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to parameter tuning and regression}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```


```{r setup}
library(ImbLassoRcpp)
```

The goal of ImbLassoRcpp is to handle imbalanced distribution in the binary outcome by employing stratified cross-validation and/or SMOTE.

## Example

### 0. Preparation

I am going to apply the functions included in the `ImbLassoRcpp` package to the data edited based on the `Vehicle` from `mlbench` package. The details of the original dataset can be found [here](https://search.r-project.org/CRAN/refmans/mlbench/html/Vehicle.html).

In order to construct a dataset with imbalanced distributed binary outcome, I collapsed all the three categories in the `Vehicle$Class` other than "bus" together, and randomly removed 150 observations from the "bus" category. In this way, the data now has 9.8% (<10%) of observations with "bus" class.

```{r}
library(mlbench)
data("Vehicle")

# table(Vehicle$Class)
# bus opel saab  van 
# 218  212  217  199

bus_id <- which(Vehicle$Class == "bus")

set.seed(7045)
imbdata <- Vehicle[-sample(bus_id, 150),]
y <- as.integer(imbdata$Class == "bus")
# mean(y) # 0.09770115

X <- data.frame(lapply(imbdata[,which(colnames(imbdata) != "Class")], scale))
```

`par_smote_cv_lasso` employs parallel computing to perform k-fold cross-validation for LASSO regression on datasets with an imbalanced binary outcome, enabling the tuning of the regularization parameter,\lambda.

When the lambda sequence is not supplied, `lambda_gen`, embeded in the functions, will produce a decreasing lambda sequence with a length of K for LASSO, based on the feature matrix X and binary outcome y.

```{r}
library(ImbLassoRcpp)

# construct data with consideration of stratified cv and SMOTE
cv_smote_data_list <- list(
  # without stratified for cross-validation and without SMOTE (reference)
  stratified_cv_smote(as.matrix(X), y, stratified = F, SMOTE = F),
  # without stratified for cross-validation and with SMOTE
  stratified_cv_smote(as.matrix(X), y, stratified = F, SMOTE = T),
  # with stratified for cross-validation and without SMOTE
  stratified_cv_smote(as.matrix(X), y, stratified = T, SMOTE = F),
  # with stratified for cross-validation and with SMOTE
  stratified_cv_smote(as.matrix(X), y, stratified = T, SMOTE = T)
)
# do parallel computing for parameter tuning of lambda
smote_cv_lasso_list <- lapply(cv_smote_data_list, par_smote_cv_lasso)
```

### 1. Parameter tuning

`plot.cv.smote.lasso`

```{r, fig.width=8, fig.height=6}
par(mfrow = c(2,2))
plot.cv.smote.lasso(smote_cv_lasso_list[[1]], main = "Stratified = F, SMOTE = F")
plot.cv.smote.lasso(smote_cv_lasso_list[[2]], main = "Stratified = F, SMOTE = T")
plot.cv.smote.lasso(smote_cv_lasso_list[[3]], main = "Stratified = T, SMOTE = F")
plot.cv.smote.lasso(smote_cv_lasso_list[[4]], main = "Stratified = T, SMOTE = T")

```

`print.cv.smote.lasso`

```{r}
print.cv.smote.lasso(smote_cv_lasso_list[[1]])
print.cv.smote.lasso(smote_cv_lasso_list[[2]])
print.cv.smote.lasso(smote_cv_lasso_list[[3]])
print.cv.smote.lasso(smote_cv_lasso_list[[4]])
```

### 2. Final model

`summary.cv.smote.lasso`

```{r}
summary.cv.smote.lasso(smote_cv_lasso_list[[1]])
summary.cv.smote.lasso(smote_cv_lasso_list[[2]])
summary.cv.smote.lasso(smote_cv_lasso_list[[3]])
summary.cv.smote.lasso(smote_cv_lasso_list[[4]])
```
